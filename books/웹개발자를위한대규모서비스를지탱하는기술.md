# 개요

* 일본 하테라는 서비스 회사의 인턴 교육용 자료를 책으로 엮은 것이다.
* 대략 2010년 기준으로 쓰여진 책이지만 22년 기준으로도 기본은 통한다.
* 책이 기준으로 한 하테나의 규모는 월간 사용자 1500만명. 하드웨어 서버 500대 이상. 트래픽은 피크기준 430Mbps, 월 요청 수 수십 억, 데이터는 기가~테라바이트급
* 당시 기준 구글, 페이스북은 테라~페타바이트급
* 하테나가 대규모라면 구글은 초대규모
* DB는 tag 테이블이 5천만row (5GB), bookmark 테이블 4500만 (5.5GB) 등 데이터량이 많은 테이블이 천만단위 row, 용량은 GB 단위.



# Chap01 대규모 웹 서비스 개발 오리엔테이션



## 강의1 대규모 서비스와 소규모 서비스

* 대규모가 되면서 가장 먼저 떠오르는 것은 확장성, 부하분산
* 확장에 관해서는 스케일아웃 전략이 기본이 됨
  * 스케일업은 성능의 한계가 존재하며 비용도 비쌈
  * 반면 RDB와 같이 데이터 정합성을 위해 스케일아웃이 힘든 자원도 존재
* 스케일아웃을 통해 장비가 늘어나면 그만큼 고장나는 장비도 많아지므로 장비 몇 대가 고장나더라도 서비스에 영향이 없도록 하는 것이 중요
  * failover, HA
* 데이터가 많아지면 한 번에 메모리에 올릴 수가 없게되고 cache miss가 나기 시작하며 IO 대기가 점점 늘어나면서 서비스가 본격적으로 느려지게됨



## 강의2 성장하는 서비스와 대규모화의 벽

* 하테나는 PC 1대에 일반적인 ADSL 회선으로 시작
* 서비스가 커지며 라우터는 Linux 박스로 저가에 구축, 부하분산은 apache의 mod_rewrite로 대용, DB분산은 mysql replication 사용 하며 대응
  * 서버가 떨어지면 자전거타고 서버실로 달려가 사람이 응급처치
* 다중화를 위해 로드밸런서+가동감시를 할 수 있는 LVS + keepalived 도입. LB를 각 부문에 도입하며 개선. OS 가상화 도입. 늘어나는 서버를 관리하기 위한 자체 관리시스템 개발. 애플리케이션 단에서는 로직 개선, 자체 검색 엔진 개발. DB레벨에서는 쿼리 개선, 스키마 재검토 등
* 완벽한 부하분산 체계는 비싸므로 시작단계에서는 가볍게 시작 (새로운 서비스가 성공할 가능성이 낮으므로). 하지만 웹서비스 기업의 경우 부하상승은 예측이 어렵고 대부분 갑작스럽게 나타나고 정신차려보면 이미 대응이 한 발 늦은 케이스가 많음. 따라서 일정수준의 수용능력 관리, 데이터 증가수준을 제어가능하도록 설계에 포함시키는게 중요
  * 내의견) 최소한의 비용으로 시작하면서도 추후 확장가능한 여지를 적절히 두는것이 노하우라는 건데 요즘에는 클라우드를 통해 보편화되었다고 볼 수 있다. 물론 클라우드를 비용 최적화하여 적재적소에 쓰는것도 능력.



## 강의3 서비스 개발의 현장

* 직원 규모 40명
* 개발팀 : 서비스별로 팀이 나뉘고 한 팀의 규모는 3~4명
* 인프라팀 : 서버/인프라 운용
* 기본 부하는 서버/인프라팀이 감시하고 가능한 부분은 먼저 대응. 애플리케이션이 원인이면 두 팀이 협력하여 해결
* 커뮤니케이션은 wiki, IRC(채팅), 서버관리툴
* 개발과정
  * 데일리 미팅 및 태스크 할당
  * 테스트 프로그램은 최대한 작성. 레거시 등 테스트 작성이 다소 어려운건 적당히 타협. 원리주의적으로 100% TC 같은 방침은 아니고 현실적인 수준에서 타협
  * 테스트를 포함한 개발이 완료되면 git 에 커밋
  * 코드리뷰
  * 리뷰 후 머지하고 스테이징에서 동작확인 후 프로덕션에 반영
  * 난이도에 따라 페어 프로그래밍도 활용. 단 피로도가 높은 작업이므로 필요한 사안에만 적용
  * 초기에는 코드리뷰, 페어 프로그래밍 모두 안 했지만 치명적인 코드가 커밋되는 경우를 몇 번 겪고 도입
* 메인언어는 Perl, 검색엔진 등 세밀한 메모리 제어 및 속도가 요구되는 곳은 C/C++, 웹 클라이언트는 JS. 
  * 내의견) PHP, Ruby 등이 많이 쓰이는 것은 알고 있으나 표준화 관점에서 창업당시부터 사용한 Perl 을 권장한다고함. 언어가 늘어나면 그 만큼 관리해야하는 표준도 늘어나므로 회사 규모에 따라 합당하다고 생각됨
* 주요 미들웨어는 Linux, Apache, MySQL, memcached
* 웹 애플리케이션 프레임워크는 자체개발한 MVC 프레임워크 사용. OR Mapper도 자체 개발한 라이브러리 사용
* SCM은 git, BTS(Bug Tracking System)은 자사 git repo와 연동한 자체개발 시스템 사용

---

> 내의견) 22년과 비교해도 툴이 좀 더 발전했을뿐 근본적인 부분에서는 큰 차이가 없어보인다.



# Chap02 대규모 데이터 처리 입문

## 강의5 대규모 데이터 처리의 어려운 점

* 제1포인트 : 메모리 내에서 계산할 수 없다.
  * 이 때문에 디스크IO가 발생하고 속도가 느려진다.
  * 당시 기준 메모리는 디스크보다 데이터 탐색 속도가 10만~100만배 정도 빨랐다.
* OS는 디스크의 느림을 커버하기 위해 한 번에 1바이트씩 읽는게 아니라 특정단위 (ex. 4KB) 로 한번에 읽는다. 
* 탐색속도 뿐만 아니라 CPU와 연결된 버스의 전송속도차도 크다.

```bash
# 220517 wsl 내부에서 해본결과 (DDR4 3200 + 삼성SSD 980 PRO 1TB)
# cached reads 가 실질 메모리 전송속도
# buffered disk 가 실질 디스크 전송속도 라고 볼 수 있다.
sudo hdparm -tT /dev/sdb

/dev/sdb:
 Timing cached reads:   34978 MB in  2.00 seconds = 17512.34 MB/sec
 Timing buffered disk reads: 6972 MB in  3.00 seconds = 2323.94 MB/sec
 
# 책의 결과는 메모리가 15012MB, 7525.03 MB/sec
# HDD가 176MB, 58.37 MB/sec 이다.

# 위와 같이 SSD의 발전으로 속도차이는 매우 많이 줄었지만 그래도 메모리가 빠르다.
```

### 부하 다루기

* `추측하지 말라, 계측하라`
* 기본흐름
  1. Load Average 확인
  2. CPU, I/O 중 어느 병목인지 확인
     - CPU 문제 : 알고리즘 개선, 오류 수정
     - IO 문제 : 스왑 등 극단적으로 IO를 발생시키는 프로세스 확인, 프로그램 개선, 메모리 증설 검토. 안 되면 데이터 분산, 캐시서버 도입 검토
* OS 튜닝이란 부하의 원인을 파악하여 제거하는 것.
  * 튜닝의 본래의미는 `병목이 발견되면 이를 제거하는 작업`
  * HW/SW가 본래의 성능을 낼 수 있도록 조정하는 작업
* I/O 성능을 개선하기 위해 확인이 필요한 것
  * 메모리를 증설하여 캐시 영역을 확보해 대응할 수 있는가
  * 원래 데이터량이 너무 많지 않은가
  * 어플리케이션의 IO 알고리즘을 변경할 필요가 있는가

## 강의6 규모조정의 요소

* AP서버는 일반적인 CPU 부하가 걸리며 스케일아웃 + LB 로 분산하여 해결
* DB는 보통 IO 부하가 문제가 되며 읽기는 replica 등으로 분산할 수 있지만 데이터 일치가 잠시 깨지는 문제가 있을 수 있고 (semi-sync 등의 대안도 존재) 쓰기 분산은 마스터가 n개가 되야하므로 더 어렵다.



## 강의7 대규모 데이터를 다루기 위한 기초지식



### 프로그램 작성 요령

* 최대한 메모리내에서 해결할 수 있도록 구성
* 데이터량 처리에 적합한 시간복잡도 알고리즘 사용
* 데이터 압축을 잘 쓰면 디스크에 접근하는 빈도를 줄일 수 있고 메모리에 캐싱하기도 유리해짐
  * 단, 그만큼 압축처리에 cpu가 사용되므로 적절한 성능치를 찾아야함
* 검색기술 (역인덱스 등) 을 활용하면 DB로만 해결이 불가능할 때 대규모 데이터에 특화된 데이터 구조 + 검색을 통해 속도향상을 달성할 수 있음
  * 내의견) RDB로 커버가 안 되서 ES를 적용하는 등의 케이스

### 전제지식

* OS 캐시 
* 분산을 고려한 RDBMS 운용
* 대규모 처리에 적합한 알고리즘과 데이터구조



# Chap03 OS 캐시와 분산

## 강의8 OS 캐시 구조

* 리눅스는 OS캐시로 페이지 캐시, 버퍼 캐시 제공
* 페이지 : OS가 가상 메모리를 확보/관리하는 단위
  * 보통 페이지 단위는 4KB
* 한 번 디스크에서 읽는 페이지는 메모리로 올려 캐시된다. 다른 프로세스가 동일 데이터를 읽을 경우 메모리의 페이지 캐시가 히트하여 빠르게 데이터를 얻을 수 있다.
  * 리눅스는 페이지 단위로 디스크를 캐싱함
  * 물리 메모리가 모자라면 LRU 등의 전략으로 안 쓰는 캐시를 파기함
* CPU의 iowait 가 발생하면 1차적으로 메모리 증설을 검토할 수 있음



## 강의9 IO부하 줄이기

* 메모리를 늘린다.
* 메모리 증설로 안 되면 복수 서버로 확장한다. 단, IO부하는 단순히 서버 숫자를 늘린다고 해결되지 않는다.
* 서버를 10대로 늘려도 모든 서버로 동일한 패턴의 요청이 들어오면 시간의 문제일뿐 동일하게 IO 부하가 발생하게된다.



## 강의10 국소성을 살리는 분산

* 그래서 그냥 늘리는게 아니라 국소성(locality)을 고려해서 분산시켜야한다.
* 예를들면 사용자들의 액세스 패턴 A, B가 있을 때 서로 접근하는 데이터 영역이 다르다면 이 영역 단위로 서버를 쪼갤 수 있다.
* 국소성을 고려한 분산 : 파티셔닝 (MySQL 도 지원)
  * 간단히는 테이블 단위로 분할 (a,b,c 테이블은 1번서버 / d,e 테이블은 2번서버)
  * 테이블 데이터 단위로 분할 : 같은 테이블에서 key의 hash 값등의 자체적인 기준으로 분할
    * 분할기준을 변경할때 데이터를 병합해야하는 어려움이 있음
  * 이런 분할을 서버 메모리 이하단위로 하면 결과적으로 모든 데이터를 메모리에 올릴 수 있으므로 IO 부하를 최소화하여 운영할 수 있음
* 분산2 : 요청 패턴에 따른 분산
  * 사용자 요청, 봇 요청과 같이 사용패턴 및 우선도가 다른 경우를 분산
    * 이 예제라면 URL이나 User-Agent값으로 부하 분산
  * 위 경우는 사용자들은 보통 최신 데이터, 인기 데이터를 조회하므로 국소성을 살리기 좋은 반면
  * 봇들은 무작위 요청등을 해서 국소성을 살리기 어려운 반면 사용자보다는 응답 속도가 늦어도 되기 때문 (봇 응답속도가 검색엔진 랭킹에 반영될 수도 있으므로 이 점은 주의 필요)
  * 이와 같이 요청 패턴에 따라 분산함으로써 성능향상을 이룰 수 있음
* OS 캐시를 고려한 운용의 경우 서버 최초 부팅 후에는 캐싱이 안 되어 있는데 바로 운영에 투입하면 서비스 지연으로 이어질 수 있으므로 의도적으로 데이터 로드 후 투입하는 절차가 필요할 수 있음. DB 파일을 의도적으로 cat한다던가 내부적으로 먼저 각종 요청을 날려 어느정도 캐싱시킨뒤에 투입한다던가.
  * 관련하여 부하테스트를 할 때도 IO로드 시간을 갖기 위해 초기 테스트는 버리고 적절한 캐시처리 완료 후 테스트하는것이 정확하다.
  * 내의견) 이건 OS 캐시뿐만 아니라 모든 캐시구조에 적용되는 이야기

---

### 부하분산과 OS의 동작원리

* 부하분산이라고 하면 네트워크, 프로그래밍의 특정 기법을 떠올릴 수 있는데 실제로 중요한 것은 OS 지식이다. OS캐시, 멀티쓰레드 & 멀티프로스세스, 가상 메모리 구조, 파일시스템 등을 파악해야 OS의 장단점과 함께 시스테 전체를 최적화할 수 있다. OS 지식이야말로 부하분산의 기초이다.
* 물론 Apache, MySQL 등의 미들웨어 사용법도 익혀야겠지만 이는 `How-to`지 기초 지식은 아니다.

# Chap04 분산을 고려한 MySQL 운용

## 강의11 인덱스 운용

* 데이터 양이 많은 경우 필드 한 개만 추가해도 용량이 크기만큼 상승하므로 스키마 설계와 변경은 세심한 주의를 기울여야한다.
* 가능한 `데이터량 < 물리 메모리`를 유지하도록 하고 부족하다면 증설을 고려한다. (스케일업)
  * 내의견) 여기서 말하는 물리 메모리도 가용한 만큼 쓰려면 buffer pool size 를 비롯해 주요 메모리 관련 MySQL 변수를 적절히 잡아야한다. (버퍼풀은 전체 메모리 75% 정도라거나 등등)
* 용량이 큰 테이블이라면 반드시 사용하는 필드와 전체 row중 일부만 필요한 필드가 있을 경우 이를 분리하여(정규화하면) 용량을 줄일 수 있다.
  * trade-off로 보통 쿼리가 복잡해지며 속도도 느려질 수 있다. 
  * 내의견) 10억 row를 가진 테이블에서 1만건 정도만 의미가 있는 8바이트 짜리 필드가 있다면 1만건이 들어간 테이블로 쪼개고 10억 row테이블에서 지우면 10억*8바이트를 확보할 수 있는 셈
* 인덱스에 흔히 쓰이는 B+ Tree는 B Tree의 파생형이며 탐색속도는 O(logn)이다. 
  * 반면에 인덱스 없이 탐색하면 선형탐색이므로 O(n) 이다. 
  * 4000만건의 테이블 검색
    * O(n) = 최대 4000만번
    * O(logn) = 최대 25.25번
  * 내의견) 세부내용은 공식문서나 Real MySQL 등의 서적 참고하자. 기본은 explain 으로 실행계획을 확인하며 쿼리를 작성하고 필요하다고 판단되는 곳에 인덱스를 생성하는 것이다. 인덱스생성도 당연히 시간과 공간을 잡아먹으므로 운영중 반영은 충분히 검토후 적용해야한다.
* 개발할 때 처음부터 실행계획을 잘 확인하며 쿼리르 작성하는 것이 기본이고
* 운영으로 넘어간 뒤에는 slow query 를 검사하여 서비스 영향도가 높은 순으로 (자주 쓰임 + 오래 걸림) 처리하는 프로세스 수립이 필요함

## 강의12 레플리케이션

* 마스터는 CUD, 슬레이브는 R 을 담당하게 하여 부하를 분산.
* 슬레이브를 여러개 두어 R 부하를 더욱 분산.
  * 단순히 랜덤 분산해버리는 것보다는 국소성을 살려서 분산함으로써 물리 메모리 안에서 처리되도록 하는 것이 중요.
* 보통 웹서비스들은 R이 많으므로 유용함.
  * 글을 쓰는사람보다 읽는 사람이 압도적으로 많다.
* 기본은 비동기로 master를 따라가므로 데이터가 반드시 정확해야하는 경우는 주의가 필요함 (slave를 보고 최신이 아니라고 판단하면 master를 보게 한다던가 처음부터 그런 시나리오는 master를 보게 한다던가)
  * 세부적으로는 semisync 처럼 결과적으로 동기식으로 동작하는 모드도 있다. 그러나 기본은 비동기.
* master의 부하가 스케일업으로 감당되지 않을 정도라면 테이블을 파니셔닝한다.
  * 단일 master에서 mysql이 제공하는 기능으로 파티셔닝을 할 수도 있고
  * DB 자체를 쪼갤 수도있고
* 또는 처음부터 메모리기반 key-value store(KVS)등의 NoSQL 을 검토한다. (Redis 등)
  * RDB가 제공하는 통계나 범용적인 정렬처리 등이 필요한게 아니라면 KVS 계열이 오버헤드도 적고 빠르며 확장하기 쉽다.
* 애플리케이션 레벨에서는 쓰기작업을 한 번에 몰아서 한다던가 (ex. bulk insert) 불필요한 쓰기 작업을 줄인다던가 지연시키는 등의 연구를 한다.



## 강의13 스케일아웃과 파티셔닝

* 메모리증설로 안 되면 파티셔닝을 검토
* 내의견) 책에서는 MySQL 서버를 여러대로 나누는 파티셔닝을 설명한다.
* t1, t2 테이블은 1번서버, t3테이블은 2번서버에 두는 식
* 주의점은 기본적으로 t1,t2 와 t3간에는 JOIN 을 할 수 없게된다는 점이다.
  * MySQL 5.1부터는 FEDERATED 테이블을 이용하면 가능하다고 한다.
  * 내의견) 근데 Managed 로 쓰는 경우는 보통 이런 기능은 쓰기가 어려워보인다. 적어도 Azure Mariadb가이드에는 없는듯. VM으로 자체구축해서 써야하는걸까?
* 대신 1번서버에서 대상 t1 id를 먼저 뽑아낸뒤 해당 id로 2번서버 t3에 where 를 걸어 뽑는식으로 JOIN 비슷하게는 동작시킬 수 있다.
  * 내의견) 하지만 트랜잭션을 걸 수 없다는 문제가 있다.

---

### 파티셔닝의 단점

* 운용이 복잡해진다. 쪼갠 개수만큼 장애 포인트가 넓어진다.
* 비용이 높아진다. 1개 DB를 운용하려면 백업3대를 포함해 총 4대가 필요하다. DB를 2개 운용하려면 4*2 = 8대가 필요해지고 DB를 늘릴수록 4의 배수로 늘어나게된다.
  * 내의견) 책에서 4대라고 설명한이유는 마스터1대 슬레이브3대가 필요해서 그렇다. 
  * m1, s1, s2, s3 라고 했을 때 m1이 다운되면 slave중 한 대를 master로 올리면된다. s1을 sm1으로 올렸다고 치고 신규장비 s4를 투입한뒤 s2는 슬레이브(R 트래픽 처리)로 계속 운용하고 s3를 중단한다음 s4로 복사하고 완료 후 s3,s4모두 sm1으로 레플리케이션을 따라가면 된다.
  * m1, s1, s2, s3 중 s1이 다운된 경우는 s2로 슬레이브 운용을 계속하고 s3를 중단한다음 신규장비 s4로 복사하고 완료 후 s3,s4모두 m1으로 레플리케이션을 따라가면 된다.
  * 반면에 m1, s1, s2 3대만 있는 경우에는 어느것이라도 1대가 고장나면 신규 투입된 s3 장비로 복사하기 위해 한 대를 더 정지해야하므로 마스터 1대만 남게되어 서비스를 중단해야한다.
    * 내의견) 이 경우도 마스터1대로 R작업까지 수행하도록 애플리케이션의 endpoint를 조정하면 되긴 할텐데 애초에 slave를 쪼갠이유가 마스터가 R까지 부담하기가 어려워서 그런거였으므로 이렇게 운용한다는 의미같다.
  * 하지만 긴급작업으로 양해를 구할 수 있는 서비스라면 비용절감을 위해 3대로만 서비스한다던가 하는 방식도 가능할 것이다.
* 이처럼 파티셔닝의 운용 난이도와 비용 vs 메모리 증설 비용을 생각해서 파티셔닝을 도입할 때는 신중해야한다.
* 애초에 RDB로 처리할 양의 데이터가 아니라고 판단된다면 NoSQL 등의 도입도 검토해야한다.



# Chap5 대규모 데이터 처리 실전 입문

## 강의14 용도특화형 인덱싱

* RDB 로 한계가 온다면...
* RDB 에서 배치로 데이터를 추출하여 별도의 인덱스 서버에서 특화된 인덱스를 만든다.
  * 검색엔진 등에 흔히 사용되는 역 인덱스 등
* 애플리케이션은 인덱스 서버에 데이터를 요청한다.
* RDB는 기본적으로 트랜잭션, 정렬, 통계, JOIN 등 범용적인 목적에 특화되어있음.
* 반면 역인덱스와 같은 용도특화형 인덱싱은 범용적이진 않지만 대용량 검색에 최적화되어있음.
* 전문 검색엔진은 아래와 같은 특성을 지니며 모두 RDB 만으로는 달성하기 어려운 요구사항이다.
  * 대량의 데이터를 검색
  * 빠르게 검색
  * 좋은 느낌(Feeling Lucky) 에 해당하는 문서를 상위로 -> 이게 어려운데 일반적으로 문서가 가진 다양한 정보를 복합적으로 활용하여 스코어링하고 해당 스코어를 기반으로 검색할 수 있다.



## 강의15 이론과 실전의 싸움

* `RDBMS에서 JOIN을 사용하지 않는 것` 은 일종의 Bad Knowhow다. RDB의 기본 개념을 무시하는 행위이기 때문이다. 이런건 보통 교과서에는 없으며 어디까지나 실전적인 노하우다.
* 반면에 역인덱스의 스코어를 구하는 작업은 벡터공간모델과 같은 고전이론을 사용해서 간단히 할 수 있다. 이런 건 교과서에 실려있다.
* 이론과 실전적인 노하우를 적재적소에 활용해야한다.
* 이론적인 예제 : 100만건의 블로그 글에서 10만건의 키워드를 찾아내 링크를 달아주려면 어떻게 하면 좋을까?
  * 전체 탐색으로 한다면 매우 오래 걸림
  * Double Array Trie를 만들어 Common Prefix Search 알고리즘을 적용하면 빠르게 생성할 수 있음 -> 적절한 데이터구조/알고리즘을 활용하여 문제를 해결하는 케이스



# Chap06 [과제] 압축 프로그래밍

* 데이터를 압축해서 다루면 그만큼 IO가 덜 발생하여 속도를 향상시킬 수 있다.
  * 내의견) trade-off로 압축처리를 위한 CPU 부하가 발생한다.
* 책에서는 정수열을 압축하는 Variable Byte Code 라는 알고리즘을 소개한다.
  * 정수열 압축은 검색엔진 개발이나 기계 학습등에서 응용된다.
  * 예를 들면 일반적인 정수형이 4바이트라고 할 때 사실 `숫자 5`는 1바이트만으로 표현이 가능하다. 이점을 활용하여 정수를 최소한의 바이트로 표현하는 것이 VB Code 다.
  * 또한 정수열인 경우는 [3, 15 20] 이란 정수열이 있으면 바로 VB Code로 만들기보다 [3, 12, 5] 와 같이 이전 숫자와의 차분으로 표현함으로써 더 큰 압축 효과를 얻을 수 있다.
* 이처럼 데이터 처리 전반에 압축을 잘 활용하면 CPU와 IO의 trade-off를 조정하여 전체 성능을 향상시킬 수 있다.
* 내의견) 예를들어 메모리가 8GB인 장비가 있고 데이터가 20GB인 DB에서 테이블 압축을 도입해서 6GB로 용량을 줄였다면 모든 데이터를 메모리에 올릴 수 있게 되니 더 빨라질까? 아니면 CPU 로드가 그만큼 높아져서 오히려 더 느려질까? 이 부분은 실험이 필요하다.



# Chap07 알고리즘 실용화

## 강의 19 알고리즘과 평가

* 알고리즘은 어떤 값 또는 값의 집합을 입력으로 하고 어떤 값 또는 값의 집합을 출력으로 하는, 명확하게 정의된(well-defined) 계산절차다.
* 컴퓨터의 자원은 유한하므로 시간, 크기 등을 고려하여 최적의 방법을 적용하기 위해 알고리즘 지식이 필요하다.
* 새로운 문제에 대처할 수 있다. 예를 들어 베이지안 필터 구현 알고리즘을 안다면 데이터를 자동분류하는 프로그램을 만들 수 있다. 메일 스팸필터, 글의 카테고리 자동 분류 등에 활용할 수 있다.
* 알고리즘의 비용중 시간복잡도는 흔히 빅오표기법 `O(1), O(logn)` 으로 나타낸다. 일반적으로 `O(nlogn)` 까지는 실용성이 있다고 본다. 
* 공간복잡도는 메모리 사용량을 나타낸다.
* 알고리즘과 데이터구조(배열, 트리, 힙, ...)는 세트로 생각하면 좋다.
  * 알고리즘에 적합한 데이터구조를 선택해야한다.
  * 예를들어 RDB의 인덱스라면 B+트리 구조를 데이터구조로 채택하고 이에 알맞은 탐색, 삽입, 정렬을 사용한다.
* 빅오표기법상 더 좋다고 결과가 항상 좋은 것은 아니다. 시간복잡도는 더 높더라도 단순한 방법이 더 나을 수도 있다.
  * 빅오표기법에는 상수항을 무시하므로 실제 시나리오에서 상수항을 무시할 정도로 n이 큰게 아니라면 오히려 시간복잡도가 더 높은게 더 빠를 수도 있다.
  * 같은 시간복잡도라도 `O(nlogn)` 을 만족하는건 알고리즘은 다양하지만 그 중에서도 퀵정렬은 특성상 CPU 캐시의 사용이 용이하여 일반적으로 가장 빠르다고 한다. 이는 상수항이 빠른 예로 볼 수 있다.
  * 하테나의 사례로는 증분 검색 기능이 필요한 확장도구를 만들었는데 데이터량이 많다면 1만건 이상이 되니 Suffix Array 라는 구조를 초기에 검토했다. 이는 텍스트 데이터를 고속을 검색하기 위해 잘 알려진 데이터 구조였는데 단점은 전처리에 많은 시간이 필요하다. 실제로 적용했더니 데이터가 추가될 때마다 전처리를 수행하니 머신에 부하가 많이 걸려 별로 속도가 빠르지 않았다. 대신 내장된 SQLite 에 sql에 흔히 쓰이는 like 검색 (즉, 선형탐색) 을 수행했는데 오히려 더 빨랐다. PC의 성능향상으로 1만건남짓한 데이터를 선형탐색해도 문제가 되지 않은 것이다. 이 사례의 교훈은 이론과 직감으로 추측만 해서는 안 되고 실제 측정이 필요하다는 점이다.
* 잘 알려진 알고리즘들은 보편적으로 미리 구현된 것들이 존재하므로 잘 가져다 쓰는 것도 능력이다.
* 압축은 무겁다는 이미지가 있지만 전체 처리량 관점에서는 더 유리한 경우가 많다. 어차피 데이터 작업을 위해 I/O 가 발생하면 블로킹이 발생하고 CPU는 놀게 되는데 압축을 통해 I/O 의 양을 줄이면 CPU가 그 만큼 먼저 작업을 하게 되므로 최종 처리량은 더 높아질수도 있는 것이다. 결국 CPU와 I/O의 부하를 모니터링하면서 압축을 적절히 적용하는것이 전체 처리량을 높일 수 있는 방법이다. 이 역시 추측하지말고 측정해야한다.
  * 예를 들면 HTTP 응답을 gzip 등으로 압축하여 전달하는 경우



## 강의20 하테나 다이어리의 키워드 링크

* 하테나의 키워드 링크란 사용자가 등록한 키워드를 기반으로 블로그 글을 작성하면 자동으로 키워드를 찾아 링크로 치환해주는 기능
* `하테나 다이어리는 블로그다.` -> `<a href='...'>하테나 다이어리</a>는 <a href='...'>블로그</a>다.`
  * `하테나 다이어리`, `블로그` 라는 유저 등록 키워드가 링크로 치환됨
* 간단하게 설명하면 블로그를 전체 탐색해서 키워드를 찾아 이를 anchor 태그로 치환하는 작업
* 하지만 대상 키워드는 27만건에 이르고 매일 새로운 키워드가 수백건씩 추가됨 (2009년 수치)



### 개선 절차



1. 초기구현 - 정규표현 : 사전 내의 모든 단어를 정규식으로 만들고 일괄치환 `(foo|bar|baz|...)`
   - 키워드가 늘어날 수록 정규식 처리가 느려짐. OR 구조 특성상 처리단위마다 모든 키워드를 검색해야하므로 점점 느려질 수 밖에 없음.
     - 정규표현 컴파일 속도저하 : 정규표현을 미리 만들고 캐싱해둠으로써 회피
     - 정규표현의 패턴매칭 속도저하 : 키워드 링크처리가 완료된 본문 캐싱으로 초기 회피가 됐으나 새로 추가된 키워드를 반영하려면 주기적으로 캐시를 다시 구축해야했고 딱히 조회가 없는 글들에는 캐시가 효과를 나타내기도 어려운 등 한계가 찾아옴
2. 1차 개선 - Trie의 도입 : 정규식의 패턴매칭에 따른 계산량 문제 해결을 위해 Trie 구조를 통한 매칭 구현으로 변경
   - Trie는 트리구조의 일종인 데이터 구조
   - 대상 데이터들의 공통 접두사를 모아 트리구조를 이루고 불필요한 데이터를 배제하는 것이 특징
   - 키워드들을 Trie구조로 만들어두면 대상 단어의 길이만큼만 계산하면 끝임. 입력 텍스트에 대해 선형 계산시간을 실현함.
   - 하테나는 실제로는 Trie 구조를 개선한 Aho-Corasick법(AC법)을 이용함. AC법은 Trie에서 매칭이 진행되다 도중에 실패했을 경우 되돌아오는 길의 엣지를 다시 Trie에 추가한 데이터 구조를 사용하는 방법
   - 속도는 빨라졌지만 정규표현이 제공하는 각종 옵션, 언어 자체가 제공해주던 기능을 사용할 수 없게된 만큼 유연성이 떨어졌음.
3. 2차 개선 - `Regexp::List` 도입
   - Trie에 의해 최적화된 정규표현을 생성하는 라이브러리
   - 예를 들면 `qw/foobar fooxar foozap fooza/` 라는 정규표현을 `foo(?:[bx]ar|zap?)` 라는 정규표현으로 변환해줌. 공통 접두사, 접미사가 정리되므로 단순 OR 연결 기반의 정규식보다 크게 빠름. 이는 결국 Trie의 원리임.
   - AC법처럼 계산량도 줄었지만 정규표현이 다시 가능해진 만큼 구현의 유연성이 향상됨



---

* 배울점
* 초기의 정규표현구현은 데이터가 적을 때는 문제가 없었음. 또한 구현이 단순했기 때문에 개발 공수가 작고 유연성도 높았음. 덕분에 시장의 요구사항에 맞춰 다양한 시도를 해볼 수 있었음.
* 하지만 데이터량 향상에 따라 성능문제에 봉착하게됨. 캐시 등으로 일정 수준의 회피는 가능했지만 본질적인 문제는 AC법이라는 알고리즘 변경을 통해 해결할 수 있었음.
* 거기에 `Regexp::List` 라는 라이브러리를 통해 양측의 장점을 모두 취할 수 있었음.



## 강의21 하테나 북마크의 기사 분류

* 특정한 글이 주어졌을 때 과학, 컴퓨터, 정치, 생활 등 카테고리를 분류하려면 어떻게 해야할까?
  * 대규모 문서를 보고 각각의 카테고리를 자동으로 판정하라
* 카테고리 판정에 `베이지안 필터` 를 사용함. 스팸필터 등에도 응용되는 알고리즘.
* 베이지안 필터는 텍스트 문서 등을 입력으로 받아 나이브 베이즈(Naive Bayes) 라는 알고리즘을 적용해 확률적으로 해당 문서가 어느 카테고리에 속하는지 판정하는 프로그램
* 미지의 문서의 카테고리를 판정하기 위해 과거에 분류가 끝난 데이터의 통계정보를 토대로 판정을 수행함.
  * 즉, 수동으로 정답 데이터를 주고 학습시켜두면 이를 기반으로 미지의 문서의 카테고리를 추측할 수 있게 되는 것.
  * 기계학습, 패턴인식의 기술분야라 볼 수 있음.
* 패턴인식 관련해서 흥미로운 칼럼
  * 구글은 이 패턴이 오면 이 언어로 변환하려는 기계학습의 원리에 대량의 데이터를 쏟아부어 번역엔진을 만들었는데, 아무도 중국어를 할 수 없는데도 중국어 번역 프로그램을 만들었다.
  * 즉, 이론적으로 `무엇이 옳은지` 몰라도 응용학습을 구사하여 기계학습에 전례없는 규모의 대량 데이터를 쏟아부으면 이 블랙박스에서 정답을 얻을 수 있다는 의견임.
  * 내의견) 딥러닝, 머신러닝 얘기일텐데 본래 머신러닝은 역사가 깊고 2010년에도 이 정도 수준이었다는 참고의견이 될 것 같다. 그러나 22년 현재도 자연어 번역은 갈 길이 멀다.
* 구글에서 검색할 때 볼 수 있는 스펠링 오류 수정기능역시 검색엔진의 로그를 정해 데이터로하여 학습엔진에 의해 구현되어 있을 거라고 저자는 말한다.
  * 하테나의 스펠링 오류 수정기능 구현 사례도 소개하는데 구글의 그것과 비교하면 덤 기능 정도라고 저자도 언급하고 있다.



# Chap08 하테나 키워드 링크 구현 (패스)



# Chap09 전문 검색기술 도전

* RDB 만으로 충분히 빠른 속도로 검색을 할 수 없을 때는 전문적인 검색 엔진 기술을 도입해야한다.

## 강의25 검색 시스템의 아키텍쳐

* 검색이 가능하기까지 크게 아래의 단계를 거치며 각 단계마다 과제가 있음
  1. 크롤링 : 원본 데이터를 어떻게 효율적으로 수집할까?
  2. 저장 : 장애에도 데이터가 소실되지 않도록 저장
  3. 인덱싱 : 인덱스 구조를 어떻게 만들까?
  4. 검색 : 인덱스 구조에 맞게 검색
  5. 스코어링 : 검색 결과에서 무엇을 먼저 보여줄 것인가?
  6. 결과표시 : 검색결과는 어떻게 보여줄까? 스니핏을 표시할까?
* 인덱싱과 검색을 담당하는 검색엔진은 오픈소스로도 많이 공개되어있다. 책에서는 Apache Lucene (ES의 전신) 등을 가볍게 소개한다.



### 전문 검색의 종류

* grep형
  * 검색 대상 문서를 처음부터 끝까지 전부 읽는 가장 단순하고 확실한 방법. 하지만 느림 
  * 기본적으로 텍스트의 길이가 M, 검색어의 길이가 N이면 O(MN) 만큼의 시간이 걸림
  * KMP, BM 알고리즘등 계산량을 어느 정도 개선한 방법이 존재하나 어쨋든 대량의 데이터를 검색하는데는 부적합
    * KMP : O(M+N)
    * BM : 최악 O(MN), 최선 O(N/M)
  * 장점은 인덱스 구축이 필요없으니 데이터가 변경된 직후 바로 검색이 가능하고 검색누락이 없고 병렬화(쪼개서 검색) 하거나 정규식으로 검색한다거나 유연성이 높음
* suffix형
  * 검색 가능한 형태로 검색 대상 전문을 보유
  * Trie, Suffix Tree, Suffix Array
  * 정보량이 크고 구현이 어려움
* 역 인덱스형 (Inverted Index)
  * 현재 검색 엔진의 주류
  * 간단히 말하면 단어(term)와 문서를 연관짓는 것
  * 검색하기 전에 전처리를 통해 인덱스를 만들어둬야함. 따라서 문서가 변경되도 인덱스가 갱신되야함
  * 구현방법에 따라서는 검색 누락이 생길 수 있음.
  * 이처럼 즉시성, 검색 누락 가능성이 존재하나 대규모화하기 용이하고 구현도 비교적 간단한 등 실용성이 높아 주류가 된 구조임

## 강의26 검색엔진의 내부구조

* 역 인덱스는 크게 Dictionary와 Postings 2개 파트로 나뉨
* 아래와 같은 글이 있다면
  * doc1 하테나의 마스코인 시나몬은 도쿄에 없다.
  * doc2 훗카이도에 살았던 kurain
  * doc3 하테나 교토의 시나몬에는 익숙한 kurain
  * doc4 하테나는 창업 9년째인 벤처다.
* 아래와 같은 역인덱스를 구성할 수 있다.
  * 하테나 -> 1, 3, 4
  * 시나몬 -> 1, 3
  * 교토 -> 3
  * 도쿄 -> 1
  * 훗카이도 -> 2
  * kurain -> 2, 3
* 역인덱스 좌측의 단어를 term이라 하고 term의 집합을 Dictionary라 함
* 우측의 배열은 각 term을 포함하는 문서가 몇 번인지를 나타낸 것이며 Postings 라 함.
* 시나몬으로 검색하면 1, 3번 문서를 찾아야함을 알 수 있음
* Dictionary를 만드는 법
  * 단어를 term으로 다룬다.
    * 사전 + AC법 : 미리 정의된 사전만 검색할 수 있도록 함 (ex. wikipedia가 배포하는 표제어 모음)
    * 형태소 분석
  * n-gram을 term으로 다룬다.
    * abracadabra의 3-gram : abr, bra, rac, ...
* Postings 작성법
  * 출현위치까지 저장 : Full Inverted Index
    * 스니핏, 스코어링, 필터링 처리가 용이
  * 문서ID만 저장 : Inverted File Index
    * 크기가 작고 구현이 쉬움
* 검색의 타당성 평가기준
  * 올바른 결과를 반환했는가?
    * 적합률(Precision) = 올바른 결과의 수 / 반환한 결과의 총수
  * 이것저것 망라해서 반환했는가?
    * 재현률(Recall) = 올바른 결과의 수 / 적합한 결과 총수
  * 초콜릿10개, 계파사탕 10개가 있는 상자에서 
    * 초콜릿을 10개 찾았지만 계피사탕도 5개가 딸려오면 재현률이 높은 것 -> 재현률을 높이려면 무조건 최대한 많이 찾으면 된다.
    * 초콜릿을 2개밖에 못 찾았지만 계피사탕은 0개라면 적합률이 높은 것 -> 적합률을 최대로 높이려면 초콜릿만 하나 뽑으면 된다.
    * 두 값은 trade-off 관계이며 목적에 맞게 적절한 재현률과 적합률의 균형을 찾는 것이 핵심



# Chap10 [과제] 전문 검색엔진 작성

* 스킵



# Chap11 대규모 데이터 처리를 지탱하는 서버/인프라 입문



## 강의29 엔터프라이즈 vs 웹서비스



|          | 엔터프라이즈 | 웹 서비스   |
| -------- | ------------ | ----------- |
| 트래픽   | 비교적 적음  | 굉장히 많음 |
| 성장성   | 적당한 정도  | 폭발적      |
| 신뢰성   | 매우 중요    | 99%         |
| 트랜잭션 | 많이 사용    | 덜 사용     |

