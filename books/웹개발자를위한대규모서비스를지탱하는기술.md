# 개요

* 일본 하테라는 서비스 회사의 인턴 교육용 자료를 책으로 엮은 것이다.
* 대략 2010년 기준으로 쓰여진 책이지만 22년 기준으로도 기본은 통한다.
* 책이 기준으로 한 하테나의 규모는 월간 사용자 1500만명. 하드웨어 서버 500대 이상. 트래픽은 피크기준 430Mbps, 월 요청 수 수십 억, 데이터는 기가~테라바이트급
* 당시 기준 구글, 페이스북은 테라~페타바이트급
* 하테나가 대규모라면 구글은 초대규모
* DB는 tag 테이블이 5천만row (5GB), bookmark 테이블 4500만 (5.5GB) 등 데이터량이 많은 테이블이 천만단위 row, 용량은 GB 단위.



# Chap01 대규모 웹 서비스 개발 오리엔테이션



## 강의1 대규모 서비스와 소규모 서비스

* 대규모가 되면서 가장 먼저 떠오르는 것은 확장성, 부하분산
* 확장에 관해서는 스케일아웃 전략이 기본이 됨
  * 스케일업은 성능의 한계가 존재하며 비용도 비쌈
  * 반면 RDB와 같이 데이터 정합성을 위해 스케일아웃이 힘든 자원도 존재
* 스케일아웃을 통해 장비가 늘어나면 그만큼 고장나는 장비도 많아지므로 장비 몇 대가 고장나더라도 서비스에 영향이 없도록 하는 것이 중요
  * failover, HA
* 데이터가 많아지면 한 번에 메모리에 올릴 수가 없게되고 cache miss가 나기 시작하며 IO 대기가 점점 늘어나면서 서비스가 본격적으로 느려지게됨



## 강의2 성장하는 서비스와 대규모화의 벽

* 하테나는 PC 1대에 일반적인 ADSL 회선으로 시작
* 서비스가 커지며 라우터는 Linux 박스로 저가에 구축, 부하분산은 apache의 mod_rewrite로 대용, DB분산은 mysql replication 사용 하며 대응
  * 서버가 떨어지면 자전거타고 서버실로 달려가 사람이 응급처치
* 다중화를 위해 로드밸런서+가동감시를 할 수 있는 LVS + keepalived 도입. LB를 각 부문에 도입하며 개선. OS 가상화 도입. 늘어나는 서버를 관리하기 위한 자체 관리시스템 개발. 애플리케이션 단에서는 로직 개선, 자체 검색 엔진 개발. DB레벨에서는 쿼리 개선, 스키마 재검토 등
* 완벽한 부하분산 체계는 비싸므로 시작단계에서는 가볍게 시작 (새로운 서비스가 성공할 가능성이 낮으므로). 하지만 웹서비스 기업의 경우 부하상승은 예측이 어렵고 대부분 갑작스럽게 나타나고 정신차려보면 이미 대응이 한 발 늦은 케이스가 많음. 따라서 일정수준의 수용능력 관리, 데이터 증가수준을 제어가능하도록 설계에 포함시키는게 중요
  * 내의견) 최소한의 비용으로 시작하면서도 추후 확장가능한 여지를 적절히 두는것이 노하우라는 건데 요즘에는 클라우드를 통해 보편화되었다고 볼 수 있다. 물론 클라우드를 비용 최적화하여 적재적소에 쓰는것도 능력.



## 강의3 서비스 개발의 현장

* 직원 규모 40명
* 개발팀 : 서비스별로 팀이 나뉘고 한 팀의 규모는 3~4명
* 인프라팀 : 서버/인프라 운용
* 기본 부하는 서버/인프라팀이 감시하고 가능한 부분은 먼저 대응. 애플리케이션이 원인이면 두 팀이 협력하여 해결
* 커뮤니케이션은 wiki, IRC(채팅), 서버관리툴
* 개발과정
  * 데일리 미팅 및 태스크 할당
  * 테스트 프로그램은 최대한 작성. 레거시 등 테스트 작성이 다소 어려운건 적당히 타협. 원리주의적으로 100% TC 같은 방침은 아니고 현실적인 수준에서 타협
  * 테스트를 포함한 개발이 완료되면 git 에 커밋
  * 코드리뷰
  * 리뷰 후 머지하고 스테이징에서 동작확인 후 프로덕션에 반영
  * 난이도에 따라 페어 프로그래밍도 활용. 단 피로도가 높은 작업이므로 필요한 사안에만 적용
  * 초기에는 코드리뷰, 페어 프로그래밍 모두 안 했지만 치명적인 코드가 커밋되는 경우를 몇 번 겪고 도입
* 메인언어는 Perl, 검색엔진 등 세밀한 메모리 제어 및 속도가 요구되는 곳은 C/C++, 웹 클라이언트는 JS. 
  * 내의견) PHP, Ruby 등이 많이 쓰이는 것은 알고 있으나 표준화 관점에서 창업당시부터 사용한 Perl 을 권장한다고함. 언어가 늘어나면 그 만큼 관리해야하는 표준도 늘어나므로 회사 규모에 따라 합당하다고 생각됨
* 주요 미들웨어는 Linux, Apache, MySQL, memcached
* 웹 애플리케이션 프레임워크는 자체개발한 MVC 프레임워크 사용. OR Mapper도 자체 개발한 라이브러리 사용
* SCM은 git, BTS(Bug Tracking System)은 자사 git repo와 연동한 자체개발 시스템 사용

---

> 내의견) 22년과 비교해도 툴이 좀 더 발전했을뿐 근본적인 부분에서는 큰 차이가 없어보인다.



# Chap02 대규모 데이터 처리 입문

## 강의5 대규모 데이터 처리의 어려운 점

* 제1포인트 : 메모리 내에서 계산할 수 없다.
  * 이 때문에 디스크IO가 발생하고 속도가 느려진다.
  * 당시 기준 메모리는 디스크보다 데이터 탐색 속도가 10만~100만배 정도 빨랐다.
* OS는 디스크의 느림을 커버하기 위해 한 번에 1바이트씩 읽는게 아니라 특정단위 (ex. 4KB) 로 한번에 읽는다. 
* 탐색속도 뿐만 아니라 CPU와 연결된 버스의 전송속도차도 크다.

```bash
# 220517 wsl 내부에서 해본결과 (DDR4 3200 + 삼성SSD 980 PRO 1TB)
# cached reads 가 실질 메모리 전송속도
# buffered disk 가 실질 디스크 전송속도 라고 볼 수 있다.
sudo hdparm -tT /dev/sdb

/dev/sdb:
 Timing cached reads:   34978 MB in  2.00 seconds = 17512.34 MB/sec
 Timing buffered disk reads: 6972 MB in  3.00 seconds = 2323.94 MB/sec
 
# 책의 결과는 메모리가 15012MB, 7525.03 MB/sec
# HDD가 176MB, 58.37 MB/sec 이다.

# 위와 같이 SSD의 발전으로 속도차이는 매우 많이 줄었지만 그래도 메모리가 빠르다.
```

### 부하 다루기

* `추측하지 말라, 계측하라`
* 기본흐름
  1. Load Average 확인
  2. CPU, I/O 중 어느 병목인지 확인
     - CPU 문제 : 알고리즘 개선, 오류 수정
     - IO 문제 : 스왑 등 극단적으로 IO를 발생시키는 프로세스 확인, 프로그램 개선, 메모리 증설 검토. 안 되면 데이터 분산, 캐시서버 도입 검토
* OS 튜닝이란 부하의 원인을 파악하여 제거하는 것.
  * 튜닝의 본래의미는 `병목이 발견되면 이를 제거하는 작업`
  * HW/SW가 본래의 성능을 낼 수 있도록 조정하는 작업
* I/O 성능을 개선하기 위해 확인이 필요한 것
  * 메모리를 증설하여 캐시 영역을 확보해 대응할 수 있는가
  * 원래 데이터량이 너무 많지 않은가
  * 어플리케이션의 IO 알고리즘을 변경할 필요가 있는가

## 강의6 규모조정의 요소

* AP서버는 일반적인 CPU 부하가 걸리며 스케일아웃 + LB 로 분산하여 해결
* DB는 보통 IO 부하가 문제가 되며 읽기는 replica 등으로 분산할 수 있지만 데이터 일치가 잠시 깨지는 문제가 있을 수 있고 (semi-sync 등의 대안도 존재) 쓰기 분산은 마스터가 n개가 되야하므로 더 어렵다.



## 강의7 대규모 데이터를 다루기 위한 기초지식



### 프로그램 작성 요령

* 최대한 메모리내에서 해결할 수 있도록 구성
* 데이터량 처리에 적합한 시간복잡도 알고리즘 사용
* 데이터 압축을 잘 쓰면 디스크에 접근하는 빈도를 줄일 수 있고 메모리에 캐싱하기도 유리해짐
  * 단, 그만큼 압축처리에 cpu가 사용되므로 적절한 성능치를 찾아야함
* 검색기술 (역인덱스 등) 을 활용하면 DB로만 해결이 불가능할 때 대규모 데이터에 특화된 데이터 구조 + 검색을 통해 속도향상을 달성할 수 있음
  * 내의견) RDB로 커버가 안 되서 ES를 적용하는 등의 케이스

### 전제지식

* OS 캐시 
* 분산을 고려한 RDBMS 운용
* 대규모 처리에 적합한 알고리즘과 데이터구조



# Chap03 OS 캐시와 분산

## 강의8 OS 캐시 구조

* 리눅스는 OS캐시로 페이지 캐시, 버퍼 캐시 제공
* 페이지 : OS가 가상 메모리를 확보/관리하는 단위
  * 보통 페이지 단위는 4KB
* 한 번 디스크에서 읽는 페이지는 메모리로 올려 캐시된다. 다른 프로세스가 동일 데이터를 읽을 경우 메모리의 페이지 캐시가 히트하여 빠르게 데이터를 얻을 수 있다.
  * 리눅스는 페이지 단위로 디스크를 캐싱함
  * 물리 메모리가 모자라면 LRU 등의 전략으로 안 쓰는 캐시를 파기함
* CPU의 iowait 가 발생하면 1차적으로 메모리 증설을 검토할 수 있음



## 강의9 IO부하 줄이기

* 메모리를 늘린다.
* 메모리 증설로 안 되면 복수 서버로 확장한다. 단, IO부하는 단순히 서버 숫자를 늘린다고 해결되지 않는다.
* 서버를 10대로 늘려도 모든 서버로 동일한 패턴의 요청이 들어오면 시간의 문제일뿐 동일하게 IO 부하가 발생하게된다.



## 강의10 국소성을 살리는 분산

* 그래서 그냥 늘리는게 아니라 국소성(locality)을 고려해서 분산시켜야한다.
* 예를들면 사용자들의 액세스 패턴 A, B가 있을 때 서로 접근하는 데이터 영역이 다르다면 이 영역 단위로 서버를 쪼갤 수 있다.
* 국소성을 고려한 분산 : 파티셔닝 (MySQL 도 지원)
  * 간단히는 테이블 단위로 분할 (a,b,c 테이블은 1번서버 / d,e 테이블은 2번서버)
  * 테이블 데이터 단위로 분할 : 같은 테이블에서 key의 hash 값등의 자체적인 기준으로 분할
    * 분할기준을 변경할때 데이터를 병합해야하는 어려움이 있음
  * 이런 분할을 서버 메모리 이하단위로 하면 결과적으로 모든 데이터를 메모리에 올릴 수 있으므로 IO 부하를 최소화하여 운영할 수 있음
* 분산2 : 요청 패턴에 따른 분산
  * 사용자 요청, 봇 요청과 같이 사용패턴 및 우선도가 다른 경우를 분산
    * 이 예제라면 URL이나 User-Agent값으로 부하 분산
  * 위 경우는 사용자들은 보통 최신 데이터, 인기 데이터를 조회하므로 국소성을 살리기 좋은 반면
  * 봇들은 무작위 요청등을 해서 국소성을 살리기 어려운 반면 사용자보다는 응답 속도가 늦어도 되기 때문 (봇 응답속도가 검색엔진 랭킹에 반영될 수도 있으므로 이 점은 주의 필요)
  * 이와 같이 요청 패턴에 따라 분산함으로써 성능향상을 이룰 수 있음
* OS 캐시를 고려한 운용의 경우 서버 최초 부팅 후에는 캐싱이 안 되어 있는데 바로 운영에 투입하면 서비스 지연으로 이어질 수 있으므로 의도적으로 데이터 로드 후 투입하는 절차가 필요할 수 있음. DB 파일을 의도적으로 cat한다던가 내부적으로 먼저 각종 요청을 날려 어느정도 캐싱시킨뒤에 투입한다던가.
  * 관련하여 부하테스트를 할 때도 IO로드 시간을 갖기 위해 초기 테스트는 버리고 적절한 캐시처리 완료 후 테스트하는것이 정확하다.
  * 내의견) 이건 OS 캐시뿐만 아니라 모든 캐시구조에 적용되는 이야기

---

### 부하분산과 OS의 동작원리

* 부하분산이라고 하면 네트워크, 프로그래밍의 특정 기법을 떠올릴 수 있는데 실제로 중요한 것은 OS 지식이다. OS캐시, 멀티쓰레드 & 멀티프로스세스, 가상 메모리 구조, 파일시스템 등을 파악해야 OS의 장단점과 함께 시스테 전체를 최적화할 수 있다. OS 지식이야말로 부하분산의 기초이다.
* 물론 Apache, MySQL 등의 미들웨어 사용법도 익혀야겠지만 이는 `How-to`지 기초 지식은 아니다.